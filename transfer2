import pandas as pd
import numpy as np
import plotly.express as px
import os

# =============================================================================
# PRÉPARATION DES DONNÉES
# =============================================================================

top15 = ["PARIS", "MARSEILLE", "LYON", "LILLE", "RENNES", "TOULOUSE", "BORDEAUX", "NICE",
         "STRASBOURG", "NANTES", "MONTPELLIER", "TOULON", "REIMS", "SAINT-ETIENNE", "LE HAVRE"]

# Préparation base
base_ml2 = base_ml.copy()
base_ml2 = base_ml2.rename(columns={"ville_": "Ville"})
base_ml2["Ville"] = base_ml2["Ville"].astype(str).str.strip().str.upper()
base_ml2 = base_ml2[base_ml2["Ville"].isin(top15)]

# Conversion date et période mensuelle
base_ml2["DATE"] = pd.to_datetime(base_ml2["DATE"])
base_ml2["Periode"] = base_ml2["DATE"].dt.to_period("M").dt.to_timestamp()

print(f"✓ Données filtrées : {len(base_ml2):,} transactions sur {len(top15)} villes")

# =============================================================================
# AGRÉGATION MENSUELLE PAR TYPOLOGIE
# =============================================================================

keys = ["Ville", "BIEN_NEUF", "TYPE_BIEN", "NB_PIECES_RANGE", "Periode"]

univers_mensuel = (
    base_ml2
    .groupby(keys, dropna=False)
    .agg(
        nb_transac=("ID", "size"),
        prix_moyen=("Prix_m2", "mean"),
        prix_median=("Prix_m2", "median"),
        surface_moyenne=("NB_SURF_HAB", "mean")
    )
    .reset_index()
)

print(f"✓ Agrégation mensuelle : {len(univers_mensuel):,} lignes")

# =============================================================================
# VÉRIFICATION COHÉRENCE TYPE_BIEN / NB_PIECES_RANGE
# =============================================================================

univers_mensuel["PB"] = univers_mensuel["NB_PIECES_RANGE"].astype(str).str.strip().str[:3].str.upper()
univers_mensuel["TYPE_BIEN"] = univers_mensuel["TYPE_BIEN"].astype(str).str.strip().str.upper()
mask = univers_mensuel["TYPE_BIEN"] != univers_mensuel["PB"]
lignes_supprimees = mask.sum()
univers_mensuel = univers_mensuel.loc[~mask].drop(columns="PB")

print(f"✓ Vérification cohérence : {lignes_supprimees:,} lignes incohérentes supprimées")

# =============================================================================
# COMPLÉTION DU CALENDRIER MENSUEL PAR TYPOLOGIE
# =============================================================================

def complete_months(g):
    """
    Complète la série temporelle pour avoir tous les mois entre min et max.
    Les mois sans transaction ont nb_transac=0 et prix_moyen=NaN.
    """
    g = g.sort_values("Periode").set_index("Periode")
    idx = pd.date_range(g.index.min(), g.index.max(), freq="MS")
    g = g.reindex(idx)
    
    # Forward/backward fill pour les colonnes catégorielles
    for col in ["Ville", "BIEN_NEUF", "TYPE_BIEN", "NB_PIECES_RANGE"]:
        g[col] = g[col].ffill().bfill()
    
    # Remplir nb_transac avec 0, garder prix_moyen en NaN
    g["nb_transac"] = g["nb_transac"].fillna(0)
    g["prix_moyen"] = g["prix_moyen"]  # Garde les NaN
    
    return g.reset_index().rename(columns={"index": "Periode"})


univers_complet = (
    univers_mensuel
    .groupby(["Ville", "BIEN_NEUF", "TYPE_BIEN", "NB_PIECES_RANGE"], group_keys=False)
    .apply(complete_months)
)

print(f"✓ Calendrier complété : {len(univers_complet):,} lignes")

# =============================================================================
# CALCUL DES POIDS STRUCTURELS (LASPEYRES FIXES)
# =============================================================================

poids_global = (
    univers_mensuel
    .groupby(["Ville", "BIEN_NEUF", "TYPE_BIEN", "NB_PIECES_RANGE"], as_index=False)["nb_transac"]
    .sum()
    .rename(columns={"nb_transac": "poids_total"})
)

# Normalisation par ville (chaque ville = 100%)
poids_global["poids_relatif"] = (
    poids_global
    .groupby('Ville')["poids_total"]
    .transform(lambda x: x / x.sum())
)

print(f"✓ Poids structurels calculés : {len(poids_global):,} typologies")

# Fusion des poids avec univers_complet
univers_complet = univers_complet.merge(
    poids_global,
    on=["Ville", "BIEN_NEUF", "TYPE_BIEN", "NB_PIECES_RANGE"],
    how="left"
)

# =============================================================================
# CALCUL DES INDICATRICES I_3m ET I_12m PAR TYPOLOGIE
# =============================================================================

print("\n=== CALCUL DES INDICATRICES D'ACTIVITÉ ===")

typokeys = ["Ville", "BIEN_NEUF", "TYPE_BIEN", "NB_PIECES_RANGE"]

# Tri crucial pour le rolling window
univers_complet = univers_complet.sort_values(typokeys + ["Periode"])

# Calcul des indicatrices PAR TYPOLOGIE sur toute la série temporelle
univers_complet["I_3m"] = (
    univers_complet
    .groupby(typokeys, group_keys=False)["nb_transac"]
    .transform(lambda s: (s.rolling(window=3, min_periods=1).sum() > 0).astype(int))
)

univers_complet["I_12m"] = (
    univers_complet
    .groupby(typokeys, group_keys=False)["nb_transac"]
    .transform(lambda s: (s.rolling(window=12, min_periods=6).sum() > 0).astype(int))
)

print("✓ Indicatrices I_3m et I_12m calculées par typologie")

# =============================================================================
# FORWARD-FILL DES PRIX (CRUCIAL POUR LA DIVERGENCE)
# =============================================================================

print("\n=== FORWARD-FILL DES PRIX ===")

# Pour chaque typologie, propager le dernier prix connu
univers_complet["prix_moyen_ffill"] = (
    univers_complet
    .groupby(typokeys, group_keys=False)["prix_moyen"]
    .transform(lambda s: s.ffill())
)

# Limiter le forward-fill à 6 mois maximum (optionnel mais recommandé)
univers_complet["mois_sans_prix"] = (
    univers_complet
    .groupby(typokeys, group_keys=False)["prix_moyen"]
    .transform(lambda s: s.isna().cumsum() - s.isna().cumsum().where(s.notna()).ffill().fillna(0))
)

# Si plus de 6 mois sans prix, mettre NaN même avec ffill
univers_complet.loc[univers_complet["mois_sans_prix"] > 6, "prix_moyen_ffill"] = np.nan

nb_ffill = (univers_complet["prix_moyen"].isna() & univers_complet["prix_moyen_ffill"].notna()).sum()
print(f"✓ Prix forward-fillés : {nb_ffill:,} mois utilisent un prix antérieur")

# =============================================================================
# FONCTION D'AGRÉGATION AVEC FORWARD-FILL
# =============================================================================

def calcule_prix_pondere_ville_periode(g):
    """
    Agrège les prix au niveau Ville×Periode avec pondération dynamique.
    Utilise prix_moyen_ffill pour inclure les typologies actives même sans prix récent.
    """
    g = g.copy()
    
    # SÉPARATION DES CALCULS 3m ET 12m
    
    # --- CALCUL 3 MOIS (strict : seulement les typologies avec prix récent) ---
    g_3m = g[(g["prix_moyen"].notna()) & (g["I_3m"] == 1)].copy()
    
    if len(g_3m) > 0 and g_3m["poids_relatif"].sum() > 0:
        poids_3m_norm = g_3m["poids_relatif"] / g_3m["poids_relatif"].sum()
        prix_pondere_3m = np.average(g_3m["prix_moyen"], weights=poids_3m_norm)
        nb_typo_3m = len(g_3m)
    else:
        prix_pondere_3m = np.nan
        nb_typo_3m = 0
    
    # --- CALCUL 12 MOIS (avec forward-fill : inclut typologies actives sur 12m) ---
    g_12m = g[(g["prix_moyen_ffill"].notna()) & (g["I_12m"] == 1)].copy()
    
    if len(g_12m) > 0 and g_12m["poids_relatif"].sum() > 0:
        poids_12m_norm = g_12m["poids_relatif"] / g_12m["poids_relatif"].sum()
        prix_pondere_12m = np.average(g_12m["prix_moyen_ffill"], weights=poids_12m_norm)
        nb_typo_12m = len(g_12m)
    else:
        prix_pondere_12m = np.nan
        nb_typo_12m = 0
    
    return pd.Series({
        "prix_moyen_pondere_dyn_3m": prix_pondere_3m,
        "prix_moyen_pondere_dyn_12m": prix_pondere_12m,
        "nb_typo_3m": nb_typo_3m,
        "nb_typo_12m": nb_typo_12m
    })


# =============================================================================
# AGRÉGATION PAR VILLE × PERIODE
# =============================================================================

print("\n=== AGRÉGATION PAR VILLE ET PERIODE ===")

model_agg = (
    univers_complet
    .groupby(["Ville", "Periode"], as_index=False)
    .apply(calcule_prix_pondere_ville_periode)
    .reset_index(drop=True)
)

model_agg = model_agg.sort_values(["Ville", "Periode"])

print(f"✓ Agrégation terminée : {len(model_agg):,} lignes")

# =============================================================================
# VÉRIFICATIONS ET DIAGNOSTICS
# =============================================================================

print("\n=== DIAGNOSTICS ===")

for ville in ["PARIS", "LYON", "MARSEILLE"]:
    df_ville = model_agg[model_agg["Ville"] == ville]
    
    prix_3m_valides = df_ville["prix_moyen_pondere_dyn_3m"].notna().sum()
    prix_12m_valides = df_ville["prix_moyen_pondere_dyn_12m"].notna().sum()
    
    if prix_3m_valides > 0 and prix_12m_valides > 0:
        divergence = (
            df_ville["prix_moyen_pondere_dyn_3m"] - 
            df_ville["prix_moyen_pondere_dyn_12m"]
        ).abs()
        
        periodes_divergence = (divergence > 50).sum()
        
        print(f"\n{ville:15s}")
        print(f"  Prix 3m valides          : {prix_3m_valides}/{len(df_ville)}")
        print(f"  Prix 12m valides         : {prix_12m_valides}/{len(df_ville)}")
        print(f"  Typologies moy. (3m)     : {df_ville['nb_typo_3m'].mean():.1f}")
        print(f"  Typologies moy. (12m)    : {df_ville['nb_typo_12m'].mean():.1f}")
        print(f"  Divergence moyenne       : {divergence.mean():.0f} €")
        print(f"  Divergence max           : {divergence.max():.0f} €")
        print(f"  Mois avec divergence >50€: {periodes_divergence} ({periodes_divergence/len(df_ville)*100:.1f}%)")

# =============================================================================
# BORNAGE TEMPOREL (OPTIONNEL)
# =============================================================================

model_agg = model_agg[model_agg["Periode"] < "2025-10-01"]

print(f"\n✓ Période finale : {model_agg['Periode'].min()} à {model_agg['Periode'].max()}")

# =============================================================================
# GÉNÉRATION DES GRAPHIQUES
# =============================================================================

print("\n=== GÉNÉRATION DES GRAPHIQUES ===")

output_dir = os.path.join(os.path.dirname(__file__), "results")
os.makedirs(output_dir, exist_ok=True)

for ville in model_agg["Ville"].unique():
    df_ville = model_agg[model_agg["Ville"] == ville].sort_values("Periode")

    fig = px.line(
        df_ville,
        x="Periode",
        y=["prix_moyen_pondere_dyn_3m", "prix_moyen_pondere_dyn_12m"],
        title=f"Évolution du prix au m² — {ville}",
        labels={"value": "Prix du m² (€)", "variable": "Indicateur", "Periode": "Date"},
        markers=True
    )
    
    fig.update_layout(
        title_x=0.5,
        plot_bgcolor="white",
        xaxis=dict(showgrid=True, gridcolor="#eee"),
        yaxis=dict(showgrid=True, gridcolor="#eee"),
        legend_title="Type de prix",
        height=500
    )
    
    # Sauvegarder en HTML
    output_path = os.path.join(output_dir, f"evolution_prix_{ville}.html")
    fig.write_html(output_path)
    print(f"  ✓ {ville:20s} -> {os.path.basename(output_path)}")

print(f"\n✓ Tous les graphiques sauvegardés dans : {output_dir}")
